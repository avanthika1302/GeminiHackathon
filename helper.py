{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOS+hEdt2RiXYy/xP20mUfi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avanthika1302/GeminiHackathon/blob/main/helper.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YoinueqV-UkR"
      },
      "outputs": [],
      "source": [
        "import sqlite3, re, json, requests\n",
        "from google.colab import userdata\n",
        "from google.generativeai import GenerativeModel\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "SERPER_API_KEY = userdata.get('SERPER_API_KEY')\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Function to generate insights from image and location\n",
        "def generate_description(imagefile, location):\n",
        "    prompt = \"\"\"\n",
        "    You are a professional photography assistant.\n",
        "    Analyze this photo and describe:\n",
        "    1. The scene and type of location.\n",
        "    2. The optimal time of day and weather for this type of photo.\n",
        "    3. Key photographic elements.\n",
        "    4. Ideal use case for the photo (e.g., family shoots, fashion, travel).\n",
        "    5. Add in an apt social media captions with tags to the picture as a bonus.\n",
        "    6. Suggest nearby or similar locations for taking such photos based on the user's location.\n",
        "    Return the response in JSON format with keys:\n",
        "    - desc\n",
        "    - tags\n",
        "    - OptWeather\n",
        "    - Elements\n",
        "    - UseCase\n",
        "    - SMCaption\n",
        "    - NearbySpots\n",
        "    \"\"\"\n",
        "    client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        contents=[imagefile.read(), prompt])\n",
        "    #response = model.generate_content([imagefile.read(), prompt])\n",
        "    return response.text\n",
        "\n",
        "# Parse JSON safely\n",
        "def clean_json(text):\n",
        "    try:\n",
        "        json_match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
        "        return json.loads(json_match.group()) if json_match else {}\n",
        "    except Exception as e:\n",
        "        #st.error(\"Failed to parse JSON: \" + str(e))\n",
        "        return {\"Failed to parse JSON: \" + str(e)}\n",
        "\n",
        "# Save metadata to SQLite\n",
        "def init_db(db_path):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS photos (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            name TEXT,\n",
        "            email TEXT,\n",
        "            location TEXT,\n",
        "            image_name TEXT,\n",
        "            metadata TEXT\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def insert_image_metadata(name, email, image_path, location, metadata):\n",
        "    try:\n",
        "        conn = sqlite3.connect(\"userimages.db\")\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"INSERT INTO photos (name, email, location, image_name, metadata) VALUES (?, ?, ?, ?, ?)\",\n",
        "                        (name, email, location, image_path, json.dumps(metadata)))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        return \"success\"\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "def search_similar_places(tags, location):\n",
        "    query = f\"photography spots with {', '.join(tags)} in {location}\"\n",
        "    headers = {\n",
        "        \"X-API-KEY\": SERPER_API_KEY ,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\"q\": query, \"type\": \"images\"}\n",
        "    response = requests.post(\"https://google.serper.dev/search\", headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        results = response.json()\n",
        "        return results.get(\"images\", [])[:3]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# --- Function for natural language chat ---\n",
        "def answer_question_from_json(json_string_from_vision_model: str, user_question: str) -> str:\n",
        "    \"\"\"\n",
        "    Answers a user's question based *only* on the provided JSON data.\n",
        "\n",
        "    Args:\n",
        "        json_string_from_vision_model: The JSON string output generated by the\n",
        "                                       vision model in the previous step.\n",
        "        user_question: The follow-up question asked by the user.\n",
        "\n",
        "    Returns:\n",
        "        The answer generated by the text LLM, or an error message.\n",
        "\"\"\"\n",
        "    # --- Construct the prompt for the text LLM ---\n",
        "    # This prompt explicitly tells the model to use *only* the provided JSON\n",
        "    prompt = f\"\"\"\n",
        "    You are an assistant answering questions based on the provided JSON data below,\n",
        "    which describes a photograph. Do not use any external knowledge or information\n",
        "    not present in the JSON. If the answer cannot be found in the JSON,\n",
        "    say so but also give a slightly creative within the realm of the JSON. Also do not talk about the other models performance\n",
        "\n",
        "    JSON Data:\n",
        "    ```json\n",
        "    {json_string_from_vision_model}\n",
        "    ```\n",
        "\n",
        "    User's Question:\n",
        "    \"{user_question}\"\n",
        "\n",
        "    Answer based strictly on the input data:\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Call the text LLM API ---\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "                    model=\"gemini-2.0-flash\",\n",
        "                    contents=prompt)\n",
        "\n",
        "        # Basic safety check (can be more robust)\n",
        "        if response.text:\n",
        "            return response.text.strip()\n",
        "        elif response.prompt_feedback.block_reason:\n",
        "             return f\"Blocked: {response.prompt_feedback.block_reason.name}. Cannot generate answer.\"\n",
        "        else:\n",
        "             # Handle cases where response might be empty unexpectedly\n",
        "             return \"Sorry, I could not generate an answer based on the provided information.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch potential API errors or other issues\n",
        "        print(f\"An error occurred during LLM generation: {e}\")\n",
        "        return \"Sorry, I encountered an error while trying to answer your question.\"\n"
      ]
    }
  ]
}