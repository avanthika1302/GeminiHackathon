import sqlite3, re, json, requests
from google.generativeai import GenerativeModel
import google.generativeai as genai
import toml,io
import streamlit as st
from PIL import Image

# Function to generate insights from image and location
def generate_description(imagefile, location):
    # Load the .toml file
    #secrets = toml.load("secrets.toml")

    GOOGLE_API_KEY = st.secrets['GOOGLE_API_KEY']

    prompt = """
    You are a professional photography assistant.
    Analyze this photo and describe:

    1. The scene and type of location.
    2. exact location where the pic might have been taken
    3. tags for this picture as a list
    4. The optimal time of day and weather for this type of photo.
    5. Key photographic elements.
    6. Ideal use case for the photo (e.g., family shoots, fashion, travel).
    7. Add in at least 4 different appropriate social media captions with 10 trending hashtags to the picture as a bonus.
    8. Suggest nearby or similar locations for taking such photos based on the user's location.

    Return the response in JSON format with keys:
    - desc
    - location
    - tags
    - OptWeather
    - Elements
    - UseCase
    - SMCaption
    - NearbySpots
    """
    try:
        # Configure API key
        genai.configure(api_key=GOOGLE_API_KEY)

        # Use a GenerativeModel instance
        model = genai.GenerativeModel(model_name="gemini-2.0-flash")

        # Convert bytes to PIL Image
        image = Image.open(io.BytesIO(imagefile))

        # Send the image and prompt as parts of the input
        response = model.generate_content(
            [image, prompt],
            stream=False  # Optional: stream=True for partial response
        )

    except Exception as e:
        # Catch potential API errors or other issues
        print(f"An error occurred during LLM generation: {e}")
        response = "Sorry, I encountered an error while trying to answer your question."

    return response



# Parse JSON safely
def clean_json(text):
    try:
        json_match = re.search(r"\{.*\}", text, re.DOTALL)
        return json.loads(json_match.group()) if json_match else {}
    except Exception as e:
        #st.error("Failed to parse JSON: " + str(e))
        return {"Failed to parse JSON: " + str(e)}

# Save metadata to SQLite
def init_db(db_path):
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS photos (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT,
            email TEXT,
            location TEXT,
            image BLOB,
            metadata TEXT
        )
    """)
    conn.commit()
    conn.close()

def insert_image_metadata(name, email, imagefile, location, metadata):

    db_path = "userimages.db"

    try:
        init_db(db_path)
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("INSERT INTO photos (name, email, location, image, metadata) VALUES (?, ?, ?, ?, ?)",
                        (name, email, location, imagefile, json.dumps(metadata)))
        conn.commit()
        conn.close()
        return "success"
    except Exception as e:
        return str(e)

def search_similar_places(tags, location):

    #secrets = toml.load("secrets.toml")
    SERPER_API_KEY = st.secrets['SERPER_API_KEY']

    query = f"photography spots with {', '.join(tags)} in {location}"
    headers = {
        "X-API-KEY": SERPER_API_KEY ,
        "Content-Type": "application/json"
    }
    payload = {"q": query, "type": "images"}
    response = requests.post("https://google.serper.dev/search", headers=headers, json=payload)
    if response.status_code == 200:
        results = response.json()
        return results.get("images", [])[:3]
    else:
        return []

# --- Function for natural language chat ---
def answer_question_from_json(json_string_from_vision_model: str, user_question: str) -> str:
    """
    Answers a user's question based *only* on the provided JSON data.

    Args:
        json_string_from_vision_model: The JSON string output generated by the
                                       vision model in the previous step.
        user_question: The follow-up question asked by the user.

    Returns:
        The answer generated by the text LLM, or an error message.
"""

    GOOGLE_API_KEY = st.secrets['GOOGLE_API_KEY']

    # --- Construct the prompt for the text LLM ---
    # This prompt explicitly tells the model to use *only* the provided JSON
  
    prompt = f"""
    You are an assistant answering questions based on the provided JSON data below,
    which describes a photograph. Do not use any external knowledge or information
    not present in the JSON. If the answer cannot be found in the JSON,
    say so but also give a slightly creative within the realm of the JSON. Also do not talk about the other models performance

    JSON Data:
    ```json
    {json_string_from_vision_model}
    ```

    User's Question:
    "{user_question}"

    Answer based strictly on the input data:
    """

    # --- Call the text LLM API ---
    try:
        # Configure API key
        genai.configure(api_key=GOOGLE_API_KEY)

      # Use a GenerativeModel instance
        model = genai.GenerativeModel(model_name="gemini-2.0-flash")

      # Send the image and prompt as parts of the input
        response = model.generate_content(
            prompt,
            stream=False  # Optional: stream=True for partial response
        )

        # Basic safety check (can be more robust)
        if response.text:
            return response.text.strip()
        elif response.prompt_feedback.block_reason:
             return f"Blocked: {response.prompt_feedback.block_reason.name}. Cannot generate answer."
        else:
             # Handle cases where response might be empty unexpectedly
             return "Sorry, I could not generate an answer based on the provided information."

    except Exception as e:
        # Catch potential API errors or other issues
        print(f"An error occurred during LLM generation: {e}")
        return "Sorry, I encountered an error while trying to answer your question."
